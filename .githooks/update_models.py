#!/usr/bin/env python3
"""
Fetches model data from OpenRouter API and generates aiuser/config/models.py

Usage:
    uv run .githooks/update_models.py
"""

import importlib.util
import json
import urllib.request
from pathlib import Path

OPENROUTER_API_URL = "https://openrouter.ai/api/v1/models"
REPO_ROOT = Path(__file__).parent.parent
OUTPUT_FILE = REPO_ROOT / "aiuser" / "config" / "models.py"
OVERRIDES_FILE = REPO_ROOT / "aiuser" / "config" / "models_overrides.py"


def load_overrides():
    """Load the overrides module dynamically."""
    spec = importlib.util.spec_from_file_location("models_overrides", OVERRIDES_FILE)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module


def fetch_models() -> list[dict]:
    with urllib.request.urlopen(OPENROUTER_API_URL) as response:
        data = json.loads(response.read().decode())
    return data.get("data", [])


def extract_vision_models(models: list[dict]) -> list[str]:
    vision_models = set()
    for model in models:
        input_modalities = model.get("architecture", {}).get("input_modalities", [])
        if "image" in input_modalities:
            model_id = model["id"]
            base_name = model_id.split("/")[-1] if "/" in model_id else model_id
            base_name = base_name.split(":")[0]
            vision_models.add(base_name)
    return sorted(vision_models)


def extract_tools_models(models: list[dict]) -> list[str]:
    tools_models = set()
    for model in models:
        supported_params = model.get("supported_parameters", [])
        if "tools" in supported_params:
            model_id = model["id"]
            base_name = model_id.split("/")[-1] if "/" in model_id else model_id
            base_name = base_name.split(":")[0]
            tools_models.add(base_name)
    return sorted(tools_models)


def extract_context_limits(models: list[dict]) -> dict[str, int]:
    limits = {}
    for model in models:
        model_id = model["id"]
        context_length = model.get("context_length")
        if context_length:
            base_name = model_id.split("/")[-1] if "/" in model_id else model_id
            base_name = base_name.split(":")[0]
            safe_limit = int(context_length * 0.9)
            if base_name not in limits or safe_limit > limits[base_name]:
                limits[base_name] = safe_limit
    return dict(sorted(limits.items(), key=lambda x: (-x[1], x[0])))


def format_list(items: list[str], indent: int = 4) -> str:
    """Format a list of strings as Python code."""
    if not items:
        return "[]"
    prefix = " " * indent
    lines = [f'{prefix}"{item}",' for item in items]
    return "[\n" + "\n".join(lines) + "\n]"


def format_dict(items: dict[str, int], indent: int = 4) -> str:
    """Format a dict as Python code."""
    if not items:
        return "{}"
    prefix = " " * indent
    lines = [f'{prefix}"{k}": {v},' for k, v in items.items()]
    return "{\n" + "\n".join(lines) + "\n}"


def generate_models_file(
    vision_models: list[str],
    tools_models: list[str],
    context_limits: dict[str, int],
    unsupported_logit_bias: list[str],
) -> str:
    return f"""# Auto-generated by .githooks/update_models.py
# Do not edit manually - run the script to update, or add models to models_overrides.py

VISION_SUPPORTED_MODELS = {format_list(vision_models)}

TOOLS_SUPPORTED_MODELS = {format_list(tools_models)}

OTHER_MODELS_LIMITS = {format_dict(context_limits)}

UNSUPPORTED_LOGIT_BIAS_MODELS = {format_list(unsupported_logit_bias)}
"""


def main():
    print(f"Fetching models from {OPENROUTER_API_URL}...")
    models = fetch_models()
    print(f"Found {len(models)} models")

    vision_models = extract_vision_models(models)
    print(f"Vision-capable models: {len(vision_models)}")

    tools_models = extract_tools_models(models)
    print(f"Tools-capable models: {len(tools_models)}")

    context_limits = extract_context_limits(models)
    print(f"Context limits extracted: {len(context_limits)}")

    # Load manual overrides
    overrides = load_overrides()
    unsupported_logit_bias = getattr(overrides, "UNSUPPORTED_LOGIT_BIAS_MODELS", [])
    print(f"Unsupported logit bias models: {len(unsupported_logit_bias)}")

    content = generate_models_file(
        vision_models, tools_models, context_limits, unsupported_logit_bias
    )
    OUTPUT_FILE.write_text(content)
    print(f"Written to {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
